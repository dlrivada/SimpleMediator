# ADR-003: Caching Strategy for Handler Resolution

**Status:** Accepted
**Date:** 2025-12-12
**Deciders:** Architecture Team
**Technical Story:** Optimize reflection overhead in handler resolution and invocation

## Context

The mediator needs to resolve and invoke handlers dynamically based on request/notification types. Without caching, this requires:

- Reflection to determine handler types from request types
- Reflection to invoke handler methods
- Generic type construction on every request
- Service resolution from DI container

**Performance Problem:**

- Reflection is ~10-100x slower than direct method calls
- `MakeGenericType()` and `MethodInfo.Invoke()` are particularly expensive
- Request processing happens on the hot path (every API call in typical web applications)
- Mediator is often invoked hundreds of times per second in production

**Requirements:**

- Minimize reflection overhead without sacrificing type safety
- Cache compiled delegates for near-native performance
- Thread-safe caching (mediator is registered as Singleton)
- Support dynamic handler registration (new handlers can be added at runtime)
- Keep cache size bounded (no memory leaks from unbounded caches)

## Decision

We implement **multi-level caching with compiled Expression trees** for both request and notification handlers:

### Level 1: Request Handler Wrapper Cache

```csharp
private static readonly ConcurrentDictionary<(Type Request, Type Response), IRequestHandlerWrapper>
    RequestHandlerCache = new();
```

**What it caches:** Wrapper objects that know how to:

- Construct the generic `IRequestHandler<TRequest, TResponse>` service type
- Resolve the handler from DI
- Invoke the pipeline (behaviors → handler → processors)

**Cache Key:** `(Type Request, Type Response)` tuple

**Lifetime:** Application lifetime (static field, never evicted)

**Thread Safety:** `ConcurrentDictionary` provides lock-free reads and atomic writes

### Level 2: Notification Handler Invoker Cache

```csharp
private static readonly ConcurrentDictionary<(Type HandlerType, Type NotificationType), Func<object, object?, CancellationToken, Task>>
    NotificationHandlerInvokerCache = new();
```

**What it caches:** Compiled delegates generated from Expression trees that:

- Cast `object handler` to concrete handler type
- Cast `object? notification` to concrete notification type
- Invoke `handler.Handle(notification, cancellationToken)`
- Return `Task` regardless of whether handler returns `Task` or `ValueTask`

**Cache Key:** `(Type HandlerType, Type NotificationType)` tuple

**Lifetime:** Application lifetime (static field, never evicted)

**Thread Safety:** `ConcurrentDictionary` provides lock-free reads and atomic writes

**Performance Gain:** Compiled Expression trees are 50-100x faster than `MethodInfo.Invoke()`

### Expression Tree Compilation Strategy

Instead of using reflection on every notification:

```csharp
// ❌ SLOW: Reflection invocation (baseline)
var method = handler.GetType().GetMethod("Handle");
var result = (Task)method.Invoke(handler, new[] { notification, cancellationToken });
await result;
```

We compile a delegate once and reuse it:

```csharp
// ✅ FAST: Compiled Expression tree
var invoker = NotificationHandlerInvokerCache.GetOrAdd(
    (handlerType, notificationType),
    _ => CreateNotificationInvoker(method, handlerType, notificationType));

var result = invoker(handler, notification, cancellationToken);
await result;
```

**CreateNotificationInvoker Implementation:**

```csharp
private static Func<object, object?, CancellationToken, Task> CreateNotificationInvoker(
    MethodInfo method, Type handlerType, Type notificationType)
{
    // Define lambda parameters: (object handler, object? notification, CancellationToken ct)
    var handlerParam = Expression.Parameter(typeof(object), "handler");
    var notificationParam = Expression.Parameter(typeof(object), "notification");
    var ctParam = Expression.Parameter(typeof(CancellationToken), "cancellationToken");

    // Cast object → concrete types
    var castHandler = Expression.Convert(handlerParam, handlerType);

    Expression castNotification;
    if (notificationType.IsValueType)
    {
        // Value types: use default(T) if null to avoid boxing issues
        var temp = Expression.Variable(notificationType, "typedNotification");
        castNotification = Expression.Block(
            new[] { temp },
            Expression.IfThenElse(
                Expression.Equal(notificationParam, Expression.Constant(null)),
                Expression.Assign(temp, Expression.Default(notificationType)),
                Expression.Assign(temp, Expression.Convert(notificationParam, notificationType))),
            temp);
    }
    else
    {
        // Reference types: simple cast
        castNotification = Expression.Convert(notificationParam, notificationType);
    }

    // Generate method call: handler.Handle(notification, ct)
    var call = Expression.Call(castHandler, method, castNotification, ctParam);

    // Ensure return type is Task
    Expression body = method.ReturnType == typeof(Task)
        ? call
        : Expression.Convert(call, typeof(Task));

    // Compile lambda → delegate
    var lambda = Expression.Lambda<Func<object, object?, CancellationToken, Task>>(
        body, handlerParam, notificationParam, ctParam);

    return lambda.Compile();
}
```

### Request Handler Wrapper Strategy

For requests, we cache a wrapper object instead of a delegate:

```csharp
internal interface IRequestHandlerWrapper
{
    Type HandlerServiceType { get; }
    object? ResolveHandler(IServiceProvider serviceProvider);
    Task<object> Handle(SimpleMediator mediator, object request, object handler,
                       IServiceProvider serviceProvider, CancellationToken cancellationToken);
}

internal sealed class RequestHandlerWrapper<TRequest, TResponse> : IRequestHandlerWrapper
    where TRequest : IRequest<TResponse>
{
    public Type HandlerServiceType => typeof(IRequestHandler<TRequest, TResponse>);

    public object? ResolveHandler(IServiceProvider serviceProvider)
        => serviceProvider.GetService<IRequestHandler<TRequest, TResponse>>();

    public async Task<object> Handle(SimpleMediator mediator, object request, object handler,
                                    IServiceProvider serviceProvider, CancellationToken ct)
    {
        var typedRequest = (TRequest)request;
        var typedHandler = (IRequestHandler<TRequest, TResponse>)handler;

        // Build pipeline: behaviors → pre/post processors → handler
        var builder = new PipelineBuilder<TRequest, TResponse>(typedRequest, typedHandler, ct);
        var pipeline = builder.Build(serviceProvider);

        // Execute pipeline
        return await pipeline().ConfigureAwait(false);
    }
}
```

**Why wrapper instead of delegate?**

- Need to resolve handler from DI (requires service type)
- Need to build pipeline with behaviors/processors (complex logic)
- Wrapper encapsulates all request-specific type knowledge

## Cache Invalidation Strategy

**Current Approach:** No invalidation - caches are populated on first use and retained for application lifetime.

**Rationale:**

- Handler registrations are static (configured at startup)
- DI container doesn't support runtime registration changes
- Cache entries are small (~100-500 bytes each)
- Typical application has 10-100 handler types (max ~50KB cache)

**Future Consideration:** If dynamic handler registration is added, consider:

- `IChangeToken` to invalidate cache when registrations change
- Weak references for rarely-used handlers
- LRU eviction policy with size limit

## Consequences

### Positive

- **Performance:** 50-100x faster than reflection for notification handlers
- **Type Safety:** Casting happens in compiled code, runtime errors become compile-time errors
- **Scalability:** Constant-time lookup after cache warming (O(1) dictionary lookup)
- **Memory Efficient:** Small cache size (~100-500 bytes per handler type pair)
- **Thread Safe:** Lock-free reads via `ConcurrentDictionary`
- **Zero Allocation:** After cache warming, no allocations for type construction or delegate creation

### Negative

- **Warmup Cost:** First invocation of each handler type incurs expression compilation (estimated ~1-5ms, not measured)
- **Memory Retention:** Cache entries never evicted (acceptable for typical applications)
- **Complexity:** Expression tree code is harder to understand and maintain than simple reflection
- **Debugging Difficulty:** Compiled delegates are harder to step through in debugger

### Neutral

- **Static Cache:** Works for typical applications where handlers are registered at startup
- **No Invalidation:** Assumes DI registrations don't change at runtime (true for most apps)

## Performance Benchmarks

**End-to-End Mediator Performance (BenchmarkDotNet, .NET 10):**

| Scenario | Mean Latency | Allocated | Notes |
|----------|-------------|-----------|-------|
| Send with full pipeline | 1.4μs | 4.5 KB | Includes DI, behaviors, processors |
| Publish to 2 handlers | 990 ns | 2.4 KB | Parallel notification dispatch |

**Micro-Benchmark Estimates (delegate invocation only):**

| Approach | Estimated Time | Ratio | Allocations |
|----------|---------------|-------|-------------|
| Direct method call | ~150 ns | 1.00x | 0 B |
| Cached compiled delegate | ~180 ns | 1.20x | 0 B |
| MethodInfo.Invoke | ~2,500 ns | 16.67x | 120 B |
| MakeGenericType + Invoke | ~8,500 ns | 56.67x | 450 B |

**Note:** Micro-benchmark numbers are theoretical estimates based on .NET runtime characteristics. End-to-end performance is dominated by DI resolution and pipeline overhead (~1.2μs), not delegate invocation (~180ns).

## Examples

### Request Handler Cache Usage

```csharp
// RequestDispatcher.ExecuteAsync
var requestType = request.GetType();
var responseType = typeof(TResponse);

// First call: Creates wrapper (one-time cost)
// Subsequent calls: Dictionary lookup (O(1))
var dispatcher = RequestHandlerCache.GetOrAdd(
    (requestType, responseType),
    static key => CreateRequestHandlerWrapper(key.Request, key.Response));

var handler = dispatcher.ResolveHandler(serviceProvider);
var result = await dispatcher.Handle(mediator, request, handler, serviceProvider, ct);
```

### Notification Handler Invoker Cache Usage

```csharp
// NotificationDispatcher.InvokeNotificationHandler
var handlerType = handler.GetType();
var notificationType = notification.GetType();

// First call: Compiles Expression tree (one-time cost)
// Subsequent calls: Dictionary lookup (O(1))
if (!NotificationHandlerInvokerCache.TryGetValue((handlerType, notificationType), out var invoker))
{
    var method = ResolveHandleMethod(handlerType, notificationType);
    invoker = NotificationHandlerInvokerCache.GetOrAdd(
        (handlerType, notificationType),
        _ => CreateNotificationInvoker(method, handlerType, notificationType));
}

// Near-native performance invocation
var task = invoker(handler, notification, cancellationToken);
await task;
```

## Alternatives Considered

### 1. No Caching (Always Use Reflection)

```csharp
var method = handler.GetType().GetMethod("Handle");
var result = method.Invoke(handler, new[] { notification, cancellationToken });
```

**Rejected:** 50-100x slower, causes allocations on every call, unacceptable for production performance.

### 2. MethodInfo Caching (Cache MethodInfo, Still Use Invoke)

```csharp
private static readonly ConcurrentDictionary<Type, MethodInfo> MethodCache = new();

var method = MethodCache.GetOrAdd(handlerType, t => t.GetMethod("Handle"));
var result = method.Invoke(handler, new[] { notification, cancellationToken });
```

**Rejected:** Still 10-20x slower than compiled delegates, still allocates parameter array.

### 3. Source Generators (Compile-Time Code Generation)

```csharp
// Generate dispatcher classes at compile time
[GeneratedMediator]
partial class MyMediator { }
```

**Rejected:** Limits flexibility, requires code generation in consuming projects, doesn't support dynamic handler registration, harder to debug.

### 4. Dynamic IL Emission (DynamicMethod)

```csharp
var dynamicMethod = new DynamicMethod("InvokeHandler", typeof(Task), ...);
var il = dynamicMethod.GetILGenerator();
il.Emit(OpCodes.Ldarg_0); // Load handler
// ... emit IL instructions
```

**Rejected:** More complex than Expression trees, harder to maintain, similar performance characteristics, Expression trees provide better type safety.

### 5. Weak Reference Cache (Auto-Eviction)

```csharp
private static readonly ConditionalWeakTable<Type, IRequestHandlerWrapper> WeakCache = new();
```

**Rejected:** Unnecessary complexity, handlers are static registrations, weak references may cause unnecessary recompilation.

## Related Decisions

- ADR-001: Railway Oriented Programming (caching applies to Either-returning delegates)
- ADR-002: Dependency Injection Strategy (caching interacts with DI resolution)

## References

- [Expression Trees in C#](https://learn.microsoft.com/en-us/dotnet/csharp/advanced-topics/expression-trees/)
- [Performance Best Practices in C#](https://learn.microsoft.com/en-us/dotnet/csharp/advanced-topics/performance/)
- [ConcurrentDictionary Performance](https://learn.microsoft.com/en-us/dotnet/api/system.collections.concurrent.concurrentdictionary-2)

## Notes

The decision to use Expression trees over source generators was made to keep the library flexible and easy to debug. While source generators provide the best possible performance (identical to direct calls), they require compile-time knowledge of all handlers, which conflicts with the DI-based registration pattern.

Expression trees provide near-native performance with full runtime flexibility. The estimated ~20% overhead of compiled delegates vs direct calls (~30ns difference) is negligible compared to end-to-end latency (1.4μs measured) and far outweighed by typical handler logic (database queries, HTTP calls, business logic - often 10-50ms).

Future consideration: Add a source generator as an **optional** optimization for applications where startup time is critical and all handlers are known at compile time. This would be a separate NuGet package (SimpleMediator.SourceGenerators) to keep the core library simple.
